{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from requests import Session\n",
    "import os\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "import sqlite3\n",
    "from typing import Tuple\n",
    "from geopy.distance import geodesic\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading NFIRS incidentaddress.txt into SQLite db file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WORKING_DIR = 'D:/Fire Project/data/'\n",
    "NFIRS_PATHS = ['nfirs_fire_hazmat_pdr_2020/NFIRS_FIRES_2020_022322',\n",
    "                 'USFA NFIRS 2019 Hazmat/NFIRS_FIRES_2019_011921',\n",
    "                 'USFA NFIRS 2018 Hazmat/NFIRS_FIRES_2018_110119',\n",
    "                 'USFA NFIRS 2017 Hazmat/NFIRS_FIRES_2017_020719',\n",
    "                 'USFA NFIRS 2016 Hazmat/NFIRS_FIRES_2016_02-05-2018',\n",
    "                 'USFA NFIRS 2015 Hazmat/NFIRS_FIRES_2015_20170215']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll create a local sqlite3 database file so that we can easily store our data as we add geocodes to the existing addresses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create table for incidentaddresses.\n",
    "conn = sqlite3.Connection('fire_data.db')\n",
    "cur = conn.cursor()\n",
    "cur.execute(\"\"\"CREATE TABLE IF NOT EXISTS incident_address (\n",
    "    INTEGER PRIMARY KEY,\n",
    "    INCIDENT_KEY TEXT,\n",
    "    STATE TEXT,\n",
    "    FDID INTEGER,\n",
    "    INC_DATE INTEGER,\n",
    "    INC_NO INTEGER,\n",
    "    EXP_NO INTEGER,\n",
    "    LOC_TYPE INTEGER,\n",
    "    NUM_MILE INTEGER,\n",
    "    STREET_PRE TEXT,\n",
    "    STREETNAME TEXT,\n",
    "    STREETTYPE TEXT,\n",
    "    STREETSUF TEXT,\n",
    "    APT_NO TEXT,\n",
    "    CITY TEXT,\n",
    "    STATE_ID TEXT,\n",
    "    ZIP5 INTEGER,\n",
    "    ZIP4 INTEGER,\n",
    "    X_STREET TEXT\n",
    ")\"\"\")\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll load our csv files, each called incidentaddress.txt, and put them in the same SQL table."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The datasets from 2015-2018 doesn't have an INCIDENT_KEY column, so we will construct one out of the other information in the dataset. This format, with five components, is consistent with the INCIDENT_KEY field in 2019-2020."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.Connection('fire_data.db')\n",
    "cur = conn.cursor()\n",
    "\n",
    "# Append each dataframe to existing table.\n",
    "for path in NFIRS_PATHS:\n",
    "    df = pd.read_csv(WORKING_DIR + path + '/incidentaddress.txt', \n",
    "                        sep='^',\n",
    "                        low_memory=False,\n",
    "                        # Specify alternative text encoding.\n",
    "                        encoding='ISO-8859-1')\n",
    "    \n",
    "    if len(df.columns) == 17:\n",
    "        incident_key = df.loc[:, ['STATE', 'FDID', 'INC_DATE', 'INC_NO', 'EXP_NO']].astype(str)\n",
    "        df['INCIDENT_KEY'] = incident_key.agg('_'.join, axis=1)\n",
    "    \n",
    "    df.to_sql('incident_address',\n",
    "                    conn, \n",
    "                    if_exists='append', \n",
    "                    index=False)\n",
    "    conn.commit()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
