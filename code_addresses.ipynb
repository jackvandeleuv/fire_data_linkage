{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from requests import Session\n",
    "import os\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "import sqlite3\n",
    "from typing import Tuple\n",
    "from geopy.distance import geodesic\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Geocode addresses from NY incidents"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this notebook is to link HUD REAC inspection addresses with FEMA NFIRS fire incident addresses.\n",
    "\n",
    "The data from NFIRS doesn't have longitude and latitude, so we'll add this data using the Census Bureau API so that we can compare the geographic locations of the two sets of addresses.\n",
    "\n",
    "Because we're starting by exploring data in NY in 2015-2019, this notebook will geo-code addresses only for those incidents that occurred in NY during that time frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "WORKING_DIR = 'D:/Fire Project/data/'\n",
    "NFIRS_PATHS = ['nfirs_fire_hazmat_pdr_2020/NFIRS_FIRES_2020_022322',\n",
    "                 'USFA NFIRS 2019 Hazmat/NFIRS_FIRES_2019_011921',\n",
    "                 'USFA NFIRS 2018 Hazmat/NFIRS_FIRES_2018_110119',\n",
    "                 'USFA NFIRS 2017 Hazmat/NFIRS_FIRES_2017_020719',\n",
    "                 'USFA NFIRS 2016 Hazmat/NFIRS_FIRES_2016_02-05-2018',\n",
    "                 'USFA NFIRS 2015 Hazmat/NFIRS_FIRES_2015_20170215']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function gets standard, geocoded information about matching addresses from the U.S. Census Bureau API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def code_address(address: Tuple[str], session: Session) -> dict:\n",
    "    street = address[0].upper().strip()\n",
    "    city = address[1].upper().strip()\n",
    "    state = address[2].upper().strip()\n",
    "    zipcode = str(address[3]).strip()\n",
    "    \n",
    "    BENCHMARK = \"Public_AR_Current\"\n",
    "    VINTAGE = \"Current_Current\"\n",
    "    OUTPUT_FORMAT = \"json\"\n",
    "\n",
    "    # URL encode the address components and construct the API request URL\n",
    "    URL = f\"https://geocoding.geo.census.gov/geocoder/locations/onelineaddress?address={street.replace(' ', '+')},+{city.replace(' ', '+')}%2C+{state}+{zipcode}&benchmark={BENCHMARK}&vintage={VINTAGE}&format={OUTPUT_FORMAT}\"\n",
    "\n",
    "    response = session.get(URL)\n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    else:\n",
    "        print(\"Request failed\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll start by creating a table to store the latitude and longitude data and connecting it to our existing list of addresses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.Connection('fire_data_copy.db')\n",
    "cur = conn.cursor()\n",
    "cur.execute(\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS address_geocoded (\n",
    "        id INTEGER PRIMARY KEY,\n",
    "        latitude REAL,\n",
    "        longitude REAL,\n",
    "        INCIDENT_KEY TEXT,\n",
    "        FOREIGN KEY (INCIDENT_KEY)\n",
    "            REFERENCES incident_address(INCIDENT_KEY)\n",
    "    )\n",
    "\"\"\")\n",
    "conn.commit()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need to define a function to insert the coordinate data into a SQL table once we have the information from the API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_coordinates(latitude: float, longitude: float, incident_key: str, conn) -> None:\n",
    "    cur = conn.cursor()\n",
    "    cur.execute(\"\"\"INSERT INTO address_geocoded (\n",
    "                            latitude, \n",
    "                            longitude, \n",
    "                            INCIDENT_KEY) \n",
    "                        VALUES (\n",
    "                            ?, ?, ?\n",
    "                        )\n",
    "    \"\"\", (latitude, longitude, incident_key))\n",
    "    conn.commit()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll get a list of address information from our database which we'll use to query the API and get the cooresponding sets of coordinates.\n",
    "\n",
    "In case we need to start or stop this process, we'll only get addresses that don't already have an associated longitude/latitude in our local db file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.Connection('fire_data_copy.db')\n",
    "cur = conn.cursor()\n",
    "\n",
    "cur.execute(\"\"\"\n",
    "WITH complete AS (\n",
    "    SELECT INCIDENT_KEY as key\n",
    "    FROM address_geocoded)\n",
    "SELECT ia.INCIDENT_KEY,\n",
    "    COALESCE(NUM_MILE, '') || ' ' ||\n",
    "    COALESCE(STREET_PRE, '') || ' ' ||\n",
    "    COALESCE(STREETNAME, '') || ' ' ||\n",
    "    COALESCE(STREETTYPE, '') || ' ' ||\n",
    "    COALESCE(STREETSUF, '') || ' ' ||\n",
    "    COALESCE(APT_NO, '') as street,\n",
    "    CITY as city,\n",
    "    STATE as state,\n",
    "    ZIP5 as zipcode\n",
    "FROM incident_address as ia\n",
    "WHERE ia.INCIDENT_KEY NOT IN (SELECT key FROM complete)\n",
    "    AND STATE = 'NY'\n",
    "ORDER BY RANDOM()\n",
    "\"\"\")\n",
    "ny_addresses = cur.fetchall()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll go address-by-address returned by the SELECT query and get the coordinates from the API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 1682285622.8362489\n",
      "2000 1682286067.8882256\n"
     ]
    },
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 1 column 1 (char 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\jackv\\anaconda3\\lib\\site-packages\\requests\\models.py:971\u001b[0m, in \u001b[0;36mResponse.json\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    970\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 971\u001b[0m     \u001b[39mreturn\u001b[39;00m complexjson\u001b[39m.\u001b[39mloads(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtext, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    972\u001b[0m \u001b[39mexcept\u001b[39;00m JSONDecodeError \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    973\u001b[0m     \u001b[39m# Catch JSON-related errors and raise as requests.JSONDecodeError\u001b[39;00m\n\u001b[0;32m    974\u001b[0m     \u001b[39m# This aliases json.JSONDecodeError and simplejson.JSONDecodeError\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\jackv\\anaconda3\\lib\\json\\__init__.py:346\u001b[0m, in \u001b[0;36mloads\u001b[1;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[0;32m    343\u001b[0m \u001b[39mif\u001b[39;00m (\u001b[39mcls\u001b[39m \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m object_hook \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m\n\u001b[0;32m    344\u001b[0m         parse_int \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m parse_float \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m\n\u001b[0;32m    345\u001b[0m         parse_constant \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m object_pairs_hook \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m kw):\n\u001b[1;32m--> 346\u001b[0m     \u001b[39mreturn\u001b[39;00m _default_decoder\u001b[39m.\u001b[39;49mdecode(s)\n\u001b[0;32m    347\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mcls\u001b[39m \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\jackv\\anaconda3\\lib\\json\\decoder.py:337\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[1;34m(self, s, _w)\u001b[0m\n\u001b[0;32m    333\u001b[0m \u001b[39m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[0;32m    334\u001b[0m \u001b[39mcontaining a JSON document).\u001b[39;00m\n\u001b[0;32m    335\u001b[0m \n\u001b[0;32m    336\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m--> 337\u001b[0m obj, end \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mraw_decode(s, idx\u001b[39m=\u001b[39;49m_w(s, \u001b[39m0\u001b[39;49m)\u001b[39m.\u001b[39;49mend())\n\u001b[0;32m    338\u001b[0m end \u001b[39m=\u001b[39m _w(s, end)\u001b[39m.\u001b[39mend()\n",
      "File \u001b[1;32mc:\\Users\\jackv\\anaconda3\\lib\\json\\decoder.py:355\u001b[0m, in \u001b[0;36mJSONDecoder.raw_decode\u001b[1;34m(self, s, idx)\u001b[0m\n\u001b[0;32m    354\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m--> 355\u001b[0m     \u001b[39mraise\u001b[39;00m JSONDecodeError(\u001b[39m\"\u001b[39m\u001b[39mExpecting value\u001b[39m\u001b[39m\"\u001b[39m, s, err\u001b[39m.\u001b[39mvalue) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m    356\u001b[0m \u001b[39mreturn\u001b[39;00m obj, end\n",
      "\u001b[1;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m incident_key \u001b[39m=\u001b[39m row[\u001b[39m0\u001b[39m]\n\u001b[0;32m      6\u001b[0m address \u001b[39m=\u001b[39m row[\u001b[39m1\u001b[39m:]\n\u001b[1;32m----> 7\u001b[0m census_result \u001b[39m=\u001b[39m code_address(address, session)\n\u001b[0;32m      9\u001b[0m \u001b[39mif\u001b[39;00m census_result:\n\u001b[0;32m     10\u001b[0m     matches \u001b[39m=\u001b[39m census_result[\u001b[39m'\u001b[39m\u001b[39mresult\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m'\u001b[39m\u001b[39maddressMatches\u001b[39m\u001b[39m'\u001b[39m]\n",
      "Cell \u001b[1;32mIn[3], line 16\u001b[0m, in \u001b[0;36mcode_address\u001b[1;34m(address, session)\u001b[0m\n\u001b[0;32m     14\u001b[0m response \u001b[39m=\u001b[39m session\u001b[39m.\u001b[39mget(URL)\n\u001b[0;32m     15\u001b[0m \u001b[39mif\u001b[39;00m response\u001b[39m.\u001b[39mstatus_code \u001b[39m==\u001b[39m \u001b[39m200\u001b[39m:\n\u001b[1;32m---> 16\u001b[0m     \u001b[39mreturn\u001b[39;00m response\u001b[39m.\u001b[39;49mjson()\n\u001b[0;32m     17\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     18\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mRequest failed\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\jackv\\anaconda3\\lib\\site-packages\\requests\\models.py:975\u001b[0m, in \u001b[0;36mResponse.json\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    971\u001b[0m     \u001b[39mreturn\u001b[39;00m complexjson\u001b[39m.\u001b[39mloads(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtext, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    972\u001b[0m \u001b[39mexcept\u001b[39;00m JSONDecodeError \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    973\u001b[0m     \u001b[39m# Catch JSON-related errors and raise as requests.JSONDecodeError\u001b[39;00m\n\u001b[0;32m    974\u001b[0m     \u001b[39m# This aliases json.JSONDecodeError and simplejson.JSONDecodeError\u001b[39;00m\n\u001b[1;32m--> 975\u001b[0m     \u001b[39mraise\u001b[39;00m RequestsJSONDecodeError(e\u001b[39m.\u001b[39mmsg, e\u001b[39m.\u001b[39mdoc, e\u001b[39m.\u001b[39mpos)\n",
      "\u001b[1;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)"
     ]
    }
   ],
   "source": [
    "session = requests.Session()\n",
    "count = 0\n",
    "try:\n",
    "    for row in ny_addresses:\n",
    "        incident_key = row[0]\n",
    "        address = row[1:]\n",
    "        census_result = code_address(address, session)\n",
    "\n",
    "        if census_result:\n",
    "            matches = census_result['result']['addressMatches']\n",
    "            if matches:\n",
    "                # Keep only the first match\n",
    "                matches = matches[0]\n",
    "                coordinates = matches['coordinates']\n",
    "                insert_coordinates(coordinates['y'], coordinates['x'], incident_key, conn)\n",
    "                count += 1\n",
    "                if count % 1000 == 0:\n",
    "                    print(count, time.time())\n",
    "finally:\n",
    "    session.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
